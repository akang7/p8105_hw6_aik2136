---
title: "Homework 6"
author: "Ashley Kang"
date: "11/25/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(purrr)
library(patchwork)

theme_set(theme_bw())
```

### Problem 1

Create a `city_state` variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. Modifiy `victim_race` to have categories white and `non-white`, with `white` as the reference category. Be sure that `victim_age` is numeric.

```{r import_data_1}
homicide_data = 
  read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(city_state = str_c(city, state, sep = ", "),
         solved = ifelse(disposition == "Closed by arrest", 1, 0)) %>%
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) %>% 
  mutate(victim_race = ifelse(victim_race != "White", "non-White", "White"), 
         victim_race = fct_relevel(victim_race, "White", "non-White"),
         victim_age = as.numeric(victim_age))
```

For the city of Baltimore, MD, use the `glm` function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race (as just defined) as predictors. Save the output of `glm` as an R object; apply the `broom::tidy` to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed.

```{r model_1}
balt_model =
  homicide_data %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solved ~ victim_sex + victim_race + victim_age, family = binomial, data = .)

# Obtaining CIs and exponentiating using broom::tidy
balt_model %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         OR_Lower_Bound = exp(estimate - (1.96 * std.error)),
         OR_Upper_Bound = exp(estimate + (1.96 * std.error))) %>% 
  filter(term == "victim_racenon-White") %>% 
  select(OR, OR_Lower_Bound, OR_Upper_Bound, p.value) %>% 
  knitr::kable(digits = 4)
```

In Baltimore, the odds of solving a non-White homicide victim's case is 0.44 times the odds of solving a White homicide victim's case (95% CI: 0.31-0.62).


Now run `glm` for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. Do this within a “tidy” pipeline, making use of `purrr::map`, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city. Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r all_cities_model_1}
homicide_data %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(logit_all = map(data, ~glm(solved ~ victim_sex + victim_race + victim_age, family = binomial, data = .x)), 
         logit_all = map(logit_all, broom::tidy)) %>% 
  select(-data) %>% 
  unnest() %>% 
  filter(term == "victim_racenon-White") %>% 
  mutate(or = exp(estimate), 
         or_lower = exp(estimate - 1.96*std.error), 
         or_upper = exp(estimate + 1.96*std.error), 
         city_state = fct_reorder(city_state, estimate)) %>% 
  select(city_state, or, or_lower, or_upper) %>% 
  ggplot(aes(x = city_state, y = or)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = or_lower, ymax = or_upper)) + 
  geom_hline(yintercept = 1.0, linetype = "dashed", color = "blue") + 
  coord_flip() + 
  labs(title = "ORs for solving non-White homicide vs. White homicide in various cities", 
       y = "Odds ratio", 
       x = "Location")
```


We see that Tampa, FL, Birmingham, AL, and Durham, NC report the greatest odds ratios, which are all greater than the null value of 1. This shows that the odds of solving a non-white homicide victim's case are greater than the odds of solving a white homicide victim's case. However, this association is not significant because of the wide confidence intervals that include the null value.

On the other hand, we see that Boston, MA, Omaha, NE, Oakland, CA, Pittsburgh, PA and Cincinnati, OH (in ascending order) report odds ratios less than 1, which indicates that the odds of solving a non-white homicide victim's case are less than the odds of solving a white homicide victim's case, with significance, since all of the confidence intervals do not include the null value of 1.

In general, cities with a large number of homicides (e.g. Baltimore and Chicago) have narrower confidence intervals, while cities with fewer homicides tend to have wide confidence intervals. When we have more data, we most likely have less variability, which means that our standard errors tend to be smaller and that our confidence intervals should be narrower.

### Problem 2

In this probelm, you will analyze data gathered to understand the effects of several variables on a child’s birthweight.

```{r load_clean_2}
bweight = read_csv("data/birthweight.csv") %>% 
  janitor::clean_names()

# checking for missing values using 
# sum(is.na(bweight))
# no missing values

bweight = bweight %>%  
  mutate(babysex = as.factor(babysex), 
         frace = as.factor(frace), 
         malform = as.factor(malform), 
         mrace = as.factor(mrace))
```

After importing the data, I checked for missing data. There is no missing data in the data frame. The columns that seemed appropriate for conversion from numeric values to factor variable where dichotomous or categorical variables (not appropriately continous). I converted baby's sex, father's race, the indicator of a malformation, and mother's race to factors using `as.factor`. 

##### Exploratory plots
```{r exploratory_2}
hist = bweight %>% 
  ggplot(aes(x = bwt)) + 
  geom_histogram() + 
  labs(x = "Birthweight", 
       y = "Count")

box = bweight %>% 
  ggplot(aes(y = bwt)) + 
  geom_boxplot() + 
  labs(y = "Birthweight")

wrap_elements(hist + box) + ggtitle("Histogram and boxplot of infant birthweight")
```

If we examine both the histogram and boxplot of infant birth weight, birth weight appears to be normally distributed, but there seem to be many outliers.

Calculating correlation coefficients:

```{r correlation_2}
bweight_num = select_if(bweight, is.numeric)

corr_values = list()

for (i in 1:ncol(bweight_num)) {
  corr_values[[i]] = cor(bweight_num$bwt, bweight_num[i])
}

as.data.frame(corr_values) %>% 
  gather(key = var, value = correlation) %>% 
  filter(abs(correlation) > 0.2, 
         var != "bwt") %>% 
  knitr::kable(digits = 4, 
               col.names = c("Variable", "Correlation"))
```

The table above shows the variables that have correlation coefficient greater than 0.2. These variables may have a positive, linear relationship with birthweight. These correlation coefficients will help us with our model building process 

### Model Building

*Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.*  

I will be incorporating the above "data analysis" (correlation coefficients) with hypothesized variables that I believe influence birthweight to build my model. The hypothesized variables I chose to include had "clinical significance". From the "analysis" above using correlation coefficients, I chose to include baby's length at birth (`blength`), head circumference (`blength`), gestational age (`gaweeks`), and mother's weight gain during pregnancy (`wtgain`), as these factors can influence baby's birthweight. I did not include mother's weight at delivery (`delwt`) because the average amount of weight gained by the mother during pregnancy seemed to be a more important predictor. I also included average number of cigarettes smoked during the pregnancy, sex of baby, and SES, which was measured through family monthly income. I did not want to include too many predictors, and I did not explore interactions due to issues with interpretability.

```{r model_2}
model = bweight %>% 
  lm(bwt ~ blength + bhead + gaweeks + wtgain + smoken + 
       babysex + fincome, data = .) 

bweight %>% 
  add_predictions(model) %>% 
  add_residuals(model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  labs(title = "Predicted values vs. residuals plot", 
       x = "Predicted value", 
       y = "Residuals")

```

There seems to be some clustering as well as outliers/highly influential points when I plot predicted values against residuals. It appears that the model poorly predicts low birthweights.

```{r comparing_models_2}
cv_bweight = crossv_mc(bweight, 100)

cv_bweight = cv_bweight %>% 
  mutate(my_model = map(train, ~lm(bwt ~ blength + bhead + gaweeks + wtgain +
                                     smoken + babysex + fincome, data = .x)),
         main_model = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
         interact_model = map(train, ~lm(bwt ~ bhead + blength + babysex +
                            bhead*blength + blength*babysex + bhead*babysex +
                              bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_my_model = map2_dbl(my_model, test, ~rmse(model = .x, 
                                                        data = .y)),
         rmse_main_model = map2_dbl(main_model, test, ~rmse(model = .x, 
                                                      data = .y)),
         rmse_interaction_model = map2_dbl(interact_model, test, 
                                     ~rmse(model = .x, data = .y)))

cv_bweight %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() + 
  labs(title = "Violin plots of RMSE for selected models", 
       x = "Model", 
       y = "RMSE")

```

```{r table_rmse}
cv_bweight %>%  
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  group_by(model) %>% 
  summarize(mean_rmse = mean(rmse)) %>% 
  rename("Model" = model, 
         "Mean RMSE" = mean_rmse) %>% 
  knitr::kable(digits = 4)
```

The above plot visualizes violin plots for the RMSE of my proposed model, the main effects model, and the interaction model. Based on these plots (which display RMSE values), I would choose my model over the other two. However, I would consider adding the interaction terms that were specified in the interaction model.